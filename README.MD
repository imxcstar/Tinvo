# Tinvo

**A powerful, cross-platform, and open-source LLM AI client.**

## Overview

Tinvo is designed to be a comprehensive and extensible client for various AI models, supporting both cloud-based APIs and local inference engines. Its cross-platform nature allows you to run it seamlessly on desktops, mobile devices, and even directly in your web browser.

## Features

* **Multi-Provider Support:**

  * [OpenAI](https://openai.com/)
  * [iFlytek (Xunfei)](https://www.xfyun.cn/)
  * [ONNX](https://onnx.ai/)
  * [Ollama](https://ollama.com/)
  * [Llama Models](https://llama.meta.com/)
  * Model Context Protocol (MCP) Tools Call

* **Cross-Platform Compatibility:**

  * Android
  * iOS
  * Windows
  * macOS
  * Linux
  * Web Server
  * WebAssembly (WASM)

* **Storage Support:**

  * Local
  * WebDAV

## Screenshots

![Screenshot 1](./Preview/1.png)
![Screenshot 2](./Preview/2.png)

## License

This project is licensed under the MIT License.